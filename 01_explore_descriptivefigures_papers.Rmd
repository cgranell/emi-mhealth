---
title: "R Notebook"
output: html_notebook
---

## Metadata

Required libraries and runtime environment description.

```{r load_libraries, echo=TRUE, message=FALSE, warning=FALSE}
library(emidata)
library(tidyverse)
library(tidytext)
library(kableExtra)
library(stringr)
```


```{r session_info}
devtools::session_info(include_base = TRUE)
```

This document is an EDA notebook to explore descriptive and informative figures of the dataset *papers* in the *emidata* package. Type `?papers` for information. 

## Data 

The data for the analysis is in the *papers* dataset that has `` `r nrow(papers)` `` references.

```{r data_source, echo=FALSE}
papers %>% str()
```

As part o the text analysis of papers, i.e. wordcloud and terms frequency analysis, read the abstracts from the apper and and process them to create a [tidy](https://www.jstatsoft.org/article/view/v059i10) data structure without [stop words](https://en.wikipedia.org/wiki/Stop_words).

```{r stopwords}
tidy_abstracts <- papers %>%
  select(id, filename, abstract) %>%
  arrange(id)
  
  
papers_words <- tidy_abstracts %>%
    select(id, abstract) %>%
    unnest_tokens(word, abstract)

my_stop_words <- tibble(
  word = c(
    "et",
    "al",
    "fig",
    "e.g",
    "i.e",
    "http",
    "ing",
    "pp",
    "figure",
    "based"
    ),
  lexicon = "jmir")


all_stop_words <- stop_words %>%
  bind_rows(my_stop_words)

# Get rid of numeric values (as words) from abstracts
suppressWarnings({
  no_numbers <- papers_words %>%
    filter(is.na(as.numeric(word)))
})

# Get list of words from abstracts without stopwords 
no_stop_words <- no_numbers %>%
  anti_join(all_stop_words, by = "word") 

```


```{r calculate_stopword_stats, echo=FALSE}
total_words = nrow(papers_words)
after_cleanup = nrow(no_stop_words)
```

About `r round(after_cleanup/total_words * 100)` % of the words are considered stop words.

_How many non-stop words does each abstract have?_

```{r stop_words}

non_stop_words_per_paper <- no_stop_words %>%
  group_by(id) %>%
  summarise(num_words = n()) %>%
  arrange(desc(num_words))

ggplot(non_stop_words_per_paper, aes(id, num_words)) + geom_col() 

kable(no_stop_words %>%
  group_by(id) %>%
  summarise(num_words = n()) %>%
  arrange(desc(num_words)))
```


## Search terms in the abstract

### Psychological terms

The detection matches full words using regex option `\b`.

- mental (and also e-mental)
- psycholog (`psycholog.*`, i.e. psychology, psychological)
- psychiatric
- emotional
- health (and also e-health, u-health)
- treatment(s) (and also pretreatment, post-treatment)
- disorder(s) 
- intervention(s) 
- therapy(ies)
- distress,
- affection
- depressi (`depressi.*`, i.e. depression, depressive)
- anxiety,
- ecological momentary intervention

```{r search_terms_per_abstract}
tidy_abstracts_lower <- stringr::str_to_lower(tidy_abstracts$abstract)
term_counts <- tibble(
  id = tidy_abstracts$id,
  mental = stringr::str_count(tidy_abstracts_lower, "\\bmental\\b"),
  `psycholog..` = str_count(tidy_abstracts_lower, "\\bpsycholog.*\\b"),
  psychiatric = stringr::str_count(tidy_abstracts_lower, "\\bpsychiatric\\b"),
  emotional = stringr::str_count(tidy_abstracts_lower, "\\bemotional\\b"),
  health = stringr::str_count(tidy_abstracts_lower, "\\bhealth\\b"),
  `treatment(s)` = stringr::str_count(tidy_abstracts_lower, "\\btreatments?\\b|\\bpretreatment?\\b"),
  `disorder(s)` = stringr::str_count(tidy_abstracts_lower, "\\bdisorder?\\b"),
  `intervention(s)` = stringr::str_count(tidy_abstracts_lower, "\\bintervention?\\b"),
  `therapy/ies` = stringr::str_count(tidy_abstracts_lower, "\\btherap(y|ies)\\b"),
  distress = stringr::str_count(tidy_abstracts_lower, "\\bdistress\\b"),
  affection = stringr::str_count(tidy_abstracts_lower, "\\baffection\\b"),
  `depressi..` = str_count(tidy_abstracts_lower, "\\bdepressi.*\\b"),
  anxiety = stringr::str_count(tidy_abstracts_lower, "\\banxiety\\b"))
  # emi = stringr::str_count(tidy_abstracts_lower, "\\becological momentary intervention\\b)"))
 # TODO; I cannot serach by several words separated by blanck spaces
  
```

_How often do Psychological related search keywords appear in each abstract paper?_




### Technical terms

*Search terms*: cell, mobile smartphone, smart, portable, phone*, device*, app, apps, applicat*, mhealth, uhealth, ehealth, emental, android, iphone


_How often do Computer science related search keywords appear in each abstract paper?_


## Freqeuncy analysis onf top words in the abstracts

_Word cloud of abstracts_ 
_Word cloud of top words_

